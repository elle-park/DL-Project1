{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_Model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os \n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torch.utils.data import random_split\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from functools import partial"
      ],
      "metadata": {
        "id": "Fnj38ngqt_Nz"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U \"ray[tune]\"\n",
        "from ray import tune\n",
        "from ray.tune import CLIReporter\n",
        "from ray.tune.schedulers import ASHAScheduler"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqVRKz4H1UT1",
        "outputId": "ce36f7d0-35c7-4afc-ad1a-cf301e9c8bcf"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ray[tune] in /usr/local/lib/python3.7/dist-packages (1.11.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (4.3.3)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (1.0.3)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (7.1.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (3.6.0)\n",
            "Requirement already satisfied: grpcio<=1.43.0,>=1.28.1 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (1.43.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (3.13)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (1.21.5)\n",
            "Requirement already satisfied: protobuf>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (3.17.3)\n",
            "Requirement already satisfied: redis>=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (4.2.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (21.4.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (0.8.9)\n",
            "Requirement already satisfied: tensorboardX>=1.9 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (2.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (2.23.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (1.3.5)\n",
            "Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from grpcio<=1.43.0,>=1.28.1->ray[tune]) (1.15.0)\n",
            "Requirement already satisfied: importlib-metadata>=1.0 in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.0->ray[tune]) (4.11.3)\n",
            "Requirement already satisfied: packaging>=20.4 in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.0->ray[tune]) (21.3)\n",
            "Requirement already satisfied: deprecated>=1.2.3 in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.0->ray[tune]) (1.2.13)\n",
            "Requirement already satisfied: async-timeout>=4.0.2 in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.0->ray[tune]) (4.0.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.0->ray[tune]) (3.10.0.2)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.3->redis>=3.5.0->ray[tune]) (1.14.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.0->redis>=3.5.0->ray[tune]) (3.7.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.4->redis>=3.5.0->ray[tune]) (3.0.7)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[tune]) (5.4.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[tune]) (0.18.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->ray[tune]) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->ray[tune]) (2.8.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->ray[tune]) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->ray[tune]) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->ray[tune]) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->ray[tune]) (2.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reference: Ray Tune Documentation\n",
        "https://docs.ray.io/en/latest/tune/tutorials/tune-pytorch-cifar.html"
      ],
      "metadata": {
        "id": "1tV6vFApuM-v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resnet Setup"
      ],
      "metadata": {
        "id": "P7C3cl3swcwr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_T9K7PvRrt4o",
        "outputId": "f905a60e-8266-48d5-c204-930fd3de7bb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# of params 11173962\n",
            "# of layers 21\n"
          ]
        }
      ],
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(512, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "def project1_model():\n",
        "    return ResNet(BasicBlock, [2, 2, 2, 2])\n",
        "\n",
        "def test(net):\n",
        "    totparam = 0\n",
        "    for x in filter(lambda p: p.requires_grad, net.parameters()):\n",
        "        totparam += np.prod(x.data.numpy().shape)\n",
        "    print(\"# of params\", totparam)\n",
        "    print(\"# of layers\", len(list(filter(lambda p: p.requires_grad and len(p.data.size())>1, net.parameters()))))\n",
        "\n",
        "test(project1_model())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Data"
      ],
      "metadata": {
        "id": "SVuAdSmexH4i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ROOT = '.data'\n",
        "\n",
        "def load_data(data_dir=ROOT):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomCrop(30, 2),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n",
        "    train_set = torchvision.datasets.CIFAR10(\n",
        "        root=data_dir, train=True, download=True, transform=transform)\n",
        "\n",
        "    test_set = torchvision.datasets.CIFAR10(\n",
        "        root=data_dir, train=False, download=True, transform=transform)\n",
        "\n",
        "    return train_set, test_set"
      ],
      "metadata": {
        "id": "kC9R59iRr3bV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load_data(ROOT)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6pZzFYckvUjo",
        "outputId": "263a3da4-6564-48a6-cb5e-5dfd2567f0e1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Dataset CIFAR10\n",
              "     Number of datapoints: 50000\n",
              "     Root location: .data\n",
              "     Split: Train\n",
              "     StandardTransform\n",
              " Transform: Compose(\n",
              "                ToTensor()\n",
              "                RandomHorizontalFlip(p=0.5)\n",
              "                RandomCrop(size=(32, 32), padding=2)\n",
              "                Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
              "            ), Dataset CIFAR10\n",
              "     Number of datapoints: 10000\n",
              "     Root location: .data\n",
              "     Split: Test\n",
              "     StandardTransform\n",
              " Transform: Compose(\n",
              "                ToTensor()\n",
              "                RandomHorizontalFlip(p=0.5)\n",
              "                RandomCrop(size=(32, 32), padding=2)\n",
              "                Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
              "            ))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_cifar(config, checkpoint_dir=None, data_dir=None):\n",
        "    net = project1_model()\n",
        "\n",
        "    device = \"cpu\"\n",
        "    if torch.cuda.is_available():\n",
        "        device = \"cuda:0\"\n",
        "        if torch.cuda.device_count() > 1:\n",
        "            net = nn.DataParallel(net)\n",
        "    net.to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(net.parameters(), lr=config[\"lr\"], momentum=0.9)\n",
        "\n",
        "    if checkpoint_dir:\n",
        "        model_state, optimizer_state = torch.load(\n",
        "            os.path.join(checkpoint_dir, \"checkpoint\"))\n",
        "        net.load_state_dict(model_state)\n",
        "        optimizer.load_state_dict(optimizer_state)\n",
        "\n",
        "    trainset, testset = load_data(ROOT)\n",
        "\n",
        "    test_abs = int(len(trainset) * 0.8)\n",
        "    train_subset, val_subset = random_split(\n",
        "        trainset, [test_abs, len(trainset) - test_abs])\n",
        "\n",
        "    trainloader = torch.utils.data.DataLoader(\n",
        "        train_subset,\n",
        "        batch_size=int(config[\"batch_size\"]),\n",
        "        shuffle=True,\n",
        "        num_workers=8)\n",
        "    valloader = torch.utils.data.DataLoader(\n",
        "        val_subset,\n",
        "        batch_size=int(config[\"batch_size\"]),\n",
        "        shuffle=True,\n",
        "        num_workers=8)\n",
        "\n",
        "    for epoch in range(10): \n",
        "        running_loss = 0.0\n",
        "        epoch_steps = 0\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            # get the inputs; data is a list of [inputs, labels]\n",
        "            inputs, labels = data\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # print statistics\n",
        "            running_loss += loss.item()\n",
        "            epoch_steps += 1\n",
        "            if i % 5000 == 4999:  # print every 5000 mini-batches\n",
        "                print(\"[%d, %5d] loss: %.3f\" % (epoch + 1, i + 1,\n",
        "                                                running_loss / epoch_steps))\n",
        "                # reset running_loss\n",
        "                running_loss = 0.0\n",
        "\n",
        "        # Validation loss\n",
        "        val_loss = 0.0\n",
        "        val_steps = 0\n",
        "        total = 0\n",
        "        correct = 0\n",
        "        for i, data in enumerate(valloader, 0):\n",
        "            with torch.no_grad():\n",
        "                inputs, labels = data\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "                outputs = net(inputs)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.cpu().numpy()\n",
        "                val_steps += 1\n",
        "\n",
        "        with tune.checkpoint_dir(epoch) as checkpoint_dir:\n",
        "            path = os.path.join(checkpoint_dir, \"checkpoint\")\n",
        "            torch.save((net.state_dict(), optimizer.state_dict()), path)\n",
        "\n",
        "        tune.report(loss=(val_loss / val_steps), accuracy=correct / total)\n",
        "    print(\"Finished Training\")"
      ],
      "metadata": {
        "id": "si0P-hVAzOfJ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_accuracy(net, device=\"cpu\"):\n",
        "    trainset, testset = load_data(ROOT)\n",
        "\n",
        "    testloader = torch.utils.data.DataLoader(\n",
        "        testset, batch_size=4, shuffle=False, num_workers=2)\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            images, labels = data\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = net(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    return correct / total"
      ],
      "metadata": {
        "id": "QaCo-Dib12Ld"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "AUORfq2Y2D7g"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main(num_samples=10, max_num_epochs=10, gpus_per_trial=2):\n",
        "    load_data(ROOT)\n",
        "    config = {\n",
        "        \"l1\": tune.sample_from(lambda _: 2 ** np.random.randint(2, 9)),\n",
        "        \"l2\": tune.sample_from(lambda _: 2 ** np.random.randint(2, 9)),\n",
        "        \"lr\": tune.loguniform(1e-4, 1e-1),\n",
        "        \"batch_size\": tune.choice([2, 4, 8, 16])\n",
        "    }\n",
        "    scheduler = ASHAScheduler(\n",
        "        metric=\"loss\",\n",
        "        mode=\"min\",\n",
        "        max_t=max_num_epochs,\n",
        "        grace_period=1,\n",
        "        reduction_factor=2)\n",
        "    reporter = CLIReporter(\n",
        "        parameter_columns=[\"l1\", \"l2\", \"lr\", \"batch_size\"],\n",
        "        metric_columns=[\"loss\", \"accuracy\", \"training_iteration\"])\n",
        "    result = tune.run(\n",
        "        partial(train_cifar, data_dir=ROOT),\n",
        "        resources_per_trial={\"cpu\": 2, \"gpu\": gpus_per_trial},\n",
        "        config=config,\n",
        "        num_samples=num_samples,\n",
        "        scheduler=scheduler,\n",
        "        progress_reporter=reporter)\n",
        "\n",
        "    best_trial = result.get_best_trial(\"loss\", \"min\", \"last\")\n",
        "    print(\"Best trial config: {}\".format(best_trial.config))\n",
        "    print(\"Best trial final validation loss: {}\".format(\n",
        "        best_trial.last_result[\"loss\"]))\n",
        "    print(\"Best trial final validation accuracy: {}\".format(\n",
        "        best_trial.last_result[\"accuracy\"]))\n",
        "\n",
        "    best_trained_model = project1_model()\n",
        "    device = \"cpu\"\n",
        "    if torch.cuda.is_available():\n",
        "        device = \"cuda:0\"\n",
        "        if gpus_per_trial > 1:\n",
        "            best_trained_model = nn.DataParallel(best_trained_model)\n",
        "    best_trained_model.to(device)\n",
        "\n",
        "    best_checkpoint_dir = best_trial.checkpoint.value\n",
        "    model_state, optimizer_state = torch.load(os.path.join(\n",
        "        best_checkpoint_dir, \"checkpoint\"))\n",
        "    best_trained_model.load_state_dict(model_state)\n",
        "\n",
        "    test_acc = test_accuracy(best_trained_model, device)\n",
        "    print(\"Best trial test set accuracy: {}\".format(test_acc))\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main(num_samples=10, max_num_epochs=10, gpus_per_trial=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnqCxQDI14ch",
        "outputId": "a9cbfbc2-164f-4d3a-b737-dc269ad746f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-03-25 02:52:10,203\tWARNING experiment.py:256 -- No name detected on trainable. Using DEFAULT.\n",
            "2022-03-25 02:52:10,205\tINFO registry.py:70 -- Detected unknown callable for trainable. Converting to class.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Status ==\n",
            "Current time: 2022-03-25 02:52:10 (running for 00:00:00.22)\n",
            "Memory usage on this node: 1.7/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
            "Resources requested: 2.0/2 CPUs, 0/0 GPUs, 0.0/6.68 GiB heap, 0.0/3.34 GiB objects\n",
            "Result logdir: /root/ray_results/DEFAULT_2022-03-25_02-52-10\n",
            "Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n",
            "+---------------------+----------+-----------------+------+------+-------------+--------------+\n",
            "| Trial name          | status   | loc             |   l1 |   l2 |          lr |   batch_size |\n",
            "|---------------------+----------+-----------------+------+------+-------------+--------------|\n",
            "| DEFAULT_90d48_00000 | RUNNING  | 172.28.0.2:4190 |  256 |    8 | 0.00237941  |           16 |\n",
            "| DEFAULT_90d48_00001 | PENDING  |                 |  256 |  128 | 0.0985469   |            4 |\n",
            "| DEFAULT_90d48_00002 | PENDING  |                 |   16 |  128 | 0.000290688 |            8 |\n",
            "| DEFAULT_90d48_00003 | PENDING  |                 |  128 |  256 | 0.00057894  |            2 |\n",
            "| DEFAULT_90d48_00004 | PENDING  |                 |    8 |   16 | 0.00232069  |            4 |\n",
            "| DEFAULT_90d48_00005 | PENDING  |                 |   16 |   64 | 0.0846387   |            4 |\n",
            "| DEFAULT_90d48_00006 | PENDING  |                 |    8 |    4 | 0.000981326 |            2 |\n",
            "| DEFAULT_90d48_00007 | PENDING  |                 |   32 |    8 | 0.00232085  |           16 |\n",
            "| DEFAULT_90d48_00008 | PENDING  |                 |  256 |    4 | 0.00174613  |            8 |\n",
            "| DEFAULT_90d48_00009 | PENDING  |                 |   16 |  256 | 0.000143586 |            8 |\n",
            "+---------------------+----------+-----------------+------+------+-------------+--------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=4190)\u001b[0m Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to .data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(func pid=4190)\u001b[0m \r  0%|          | 0/170498071 [00:00<?, ?it/s]\n",
            "  0%|          | 1024/170498071 [00:00<7:49:08, 6057.06it/s]\n",
            "  0%|          | 33792/170498071 [00:00<24:40, 115143.70it/s]\n",
            "  0%|          | 82944/170498071 [00:00<14:45, 192502.21it/s]\n",
            "  0%|          | 214016/170498071 [00:00<06:48, 417249.43it/s]\n",
            "  0%|          | 443392/170498071 [00:00<03:47, 746936.24it/s]\n",
            "  1%|          | 902144/170498071 [00:01<02:01, 1398017.63it/s]\n",
            "  1%|          | 1819648/170498071 [00:01<01:02, 2680910.47it/s]\n",
            "  2%|▏         | 3671040/170498071 [00:01<00:31, 5246472.57it/s]\n",
            "  4%|▎         | 6374400/170498071 [00:01<00:19, 8505414.87it/s]\n",
            "  5%|▌         | 8586240/170498071 [00:01<00:16, 9843347.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Status ==\n",
            "Current time: 2022-03-25 02:52:15 (running for 00:00:05.27)\n",
            "Memory usage on this node: 2.1/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
            "Resources requested: 2.0/2 CPUs, 0/0 GPUs, 0.0/6.68 GiB heap, 0.0/3.34 GiB objects\n",
            "Result logdir: /root/ray_results/DEFAULT_2022-03-25_02-52-10\n",
            "Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n",
            "+---------------------+----------+-----------------+------+------+-------------+--------------+\n",
            "| Trial name          | status   | loc             |   l1 |   l2 |          lr |   batch_size |\n",
            "|---------------------+----------+-----------------+------+------+-------------+--------------|\n",
            "| DEFAULT_90d48_00000 | RUNNING  | 172.28.0.2:4190 |  256 |    8 | 0.00237941  |           16 |\n",
            "| DEFAULT_90d48_00001 | PENDING  |                 |  256 |  128 | 0.0985469   |            4 |\n",
            "| DEFAULT_90d48_00002 | PENDING  |                 |   16 |  128 | 0.000290688 |            8 |\n",
            "| DEFAULT_90d48_00003 | PENDING  |                 |  128 |  256 | 0.00057894  |            2 |\n",
            "| DEFAULT_90d48_00004 | PENDING  |                 |    8 |   16 | 0.00232069  |            4 |\n",
            "| DEFAULT_90d48_00005 | PENDING  |                 |   16 |   64 | 0.0846387   |            4 |\n",
            "| DEFAULT_90d48_00006 | PENDING  |                 |    8 |    4 | 0.000981326 |            2 |\n",
            "| DEFAULT_90d48_00007 | PENDING  |                 |   32 |    8 | 0.00232085  |           16 |\n",
            "| DEFAULT_90d48_00008 | PENDING  |                 |  256 |    4 | 0.00174613  |            8 |\n",
            "| DEFAULT_90d48_00009 | PENDING  |                 |   16 |  256 | 0.000143586 |            8 |\n",
            "+---------------------+----------+-----------------+------+------+-------------+--------------+\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  6%|▋         | 10880000/170498071 [00:01<00:14, 10894105.63it/s]\n",
            "  8%|▊         | 13386752/170498071 [00:02<00:13, 11990540.47it/s]\n",
            "  9%|▉         | 16188416/170498071 [00:02<00:11, 13259111.82it/s]\n",
            " 11%|█▏        | 19235840/170498071 [00:02<00:10, 14591158.48it/s]\n",
            " 13%|█▎        | 21578752/170498071 [00:02<00:10, 14287796.12it/s]\n",
            " 14%|█▍        | 24544256/170498071 [00:02<00:09, 15163933.16it/s]\n",
            " 16%|█▌        | 27264000/170498071 [00:02<00:09, 15341808.30it/s]\n",
            " 18%|█▊        | 30229504/170498071 [00:03<00:08, 15898006.79it/s]\n",
            " 19%|█▉        | 33113088/170498071 [00:03<00:08, 16143770.61it/s]\n",
            " 21%|██        | 36111360/170498071 [00:03<00:08, 16512049.45it/s]\n",
            " 23%|██▎       | 39109632/170498071 [00:03<00:07, 16685381.25it/s]\n",
            " 25%|██▍       | 42058752/170498071 [00:03<00:07, 16714203.71it/s]\n",
            " 26%|██▋       | 45057024/170498071 [00:03<00:07, 17003770.71it/s]\n",
            " 28%|██▊       | 47858688/170498071 [00:04<00:07, 16760295.50it/s]\n",
            " 30%|██▉       | 50594816/170498071 [00:04<00:07, 16484377.53it/s]\n",
            " 31%|███▏      | 53396480/170498071 [00:04<00:07, 16412045.47it/s]\n",
            " 33%|███▎      | 56476672/170498071 [00:04<00:06, 16835323.05it/s]\n",
            " 35%|███▍      | 59212800/170498071 [00:04<00:06, 16541661.73it/s]\n",
            " 36%|███▌      | 61654016/170498071 [00:05<00:06, 15823512.46it/s]\n",
            " 38%|███▊      | 64750592/170498071 [00:05<00:06, 16457910.72it/s]\n",
            " 40%|███▉      | 67650560/170498071 [00:05<00:06, 16484870.57it/s]\n",
            " 42%|████▏     | 70763520/170498071 [00:05<00:05, 16929842.03it/s]\n",
            " 43%|████▎     | 73843712/170498071 [00:05<00:05, 17214746.74it/s]\n",
            " 45%|████▌     | 76973056/170498071 [00:05<00:05, 17486216.95it/s]\n",
            " 47%|████▋     | 79479808/170498071 [00:06<00:05, 16599277.97it/s]\n",
            " 48%|████▊     | 82543616/170498071 [00:06<00:05, 16941386.09it/s]\n",
            " 50%|█████     | 85591040/170498071 [00:06<00:04, 17163266.14it/s]\n",
            " 52%|█████▏    | 88589312/170498071 [00:06<00:04, 17238707.09it/s]\n",
            " 54%|█████▎    | 91440128/170498071 [00:06<00:04, 17001513.83it/s]\n",
            " 55%|█████▌    | 94372864/170498071 [00:06<00:04, 16960556.11it/s]\n",
            " 57%|█████▋    | 97354752/170498071 [00:07<00:04, 17051119.01it/s]\n",
            " 59%|█████▉    | 100320256/170498071 [00:07<00:04, 17087261.86it/s]\n",
            " 61%|██████    | 103318528/170498071 [00:07<00:03, 17192383.98it/s]\n",
            " 62%|██████▏   | 106152960/170498071 [00:07<00:03, 16929015.08it/s]\n",
            " 64%|██████▍   | 109233152/170498071 [00:07<00:03, 17211412.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Status ==\n",
            "Current time: 2022-03-25 02:52:21 (running for 00:00:11.26)\n",
            "Memory usage on this node: 2.1/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
            "Resources requested: 2.0/2 CPUs, 0/0 GPUs, 0.0/6.68 GiB heap, 0.0/3.34 GiB objects\n",
            "Result logdir: /root/ray_results/DEFAULT_2022-03-25_02-52-10\n",
            "Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n",
            "+---------------------+----------+-----------------+------+------+-------------+--------------+\n",
            "| Trial name          | status   | loc             |   l1 |   l2 |          lr |   batch_size |\n",
            "|---------------------+----------+-----------------+------+------+-------------+--------------|\n",
            "| DEFAULT_90d48_00000 | RUNNING  | 172.28.0.2:4190 |  256 |    8 | 0.00237941  |           16 |\n",
            "| DEFAULT_90d48_00001 | PENDING  |                 |  256 |  128 | 0.0985469   |            4 |\n",
            "| DEFAULT_90d48_00002 | PENDING  |                 |   16 |  128 | 0.000290688 |            8 |\n",
            "| DEFAULT_90d48_00003 | PENDING  |                 |  128 |  256 | 0.00057894  |            2 |\n",
            "| DEFAULT_90d48_00004 | PENDING  |                 |    8 |   16 | 0.00232069  |            4 |\n",
            "| DEFAULT_90d48_00005 | PENDING  |                 |   16 |   64 | 0.0846387   |            4 |\n",
            "| DEFAULT_90d48_00006 | PENDING  |                 |    8 |    4 | 0.000981326 |            2 |\n",
            "| DEFAULT_90d48_00007 | PENDING  |                 |   32 |    8 | 0.00232085  |           16 |\n",
            "| DEFAULT_90d48_00008 | PENDING  |                 |  256 |    4 | 0.00174613  |            8 |\n",
            "| DEFAULT_90d48_00009 | PENDING  |                 |   16 |  256 | 0.000143586 |            8 |\n",
            "+---------------------+----------+-----------------+------+------+-------------+--------------+\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 66%|██████▌   | 112149504/170498071 [00:07<00:03, 17119187.39it/s]\n",
            " 67%|██████▋   | 114721792/170498071 [00:08<00:03, 16449022.85it/s]\n",
            " 69%|██████▉   | 117474304/170498071 [00:08<00:03, 16305311.92it/s]\n",
            " 71%|███████   | 120407040/170498071 [00:08<00:03, 16509322.09it/s]\n",
            " 72%|███████▏  | 123356160/170498071 [00:08<00:02, 16687326.18it/s]\n",
            " 74%|███████▍  | 126387200/170498071 [00:08<00:02, 16947127.14it/s]\n",
            " 76%|███████▌  | 129254400/170498071 [00:08<00:02, 16815240.71it/s]\n",
            " 78%|███████▊  | 132318208/170498071 [00:09<00:02, 17029459.79it/s]\n",
            " 79%|███████▉  | 135382016/170498071 [00:09<00:02, 17239437.88it/s]\n",
            " 81%|████████  | 138511360/170498071 [00:09<00:01, 17511498.46it/s]\n",
            " 83%|████████▎ | 141591552/170498071 [00:09<00:01, 17611233.76it/s]\n",
            " 85%|████████▍ | 144655360/170498071 [00:09<00:01, 17661236.61it/s]\n",
            " 87%|████████▋ | 147801088/170498071 [00:10<00:01, 17836198.24it/s]\n",
            " 88%|████████▊ | 150766592/170498071 [00:10<00:01, 17628747.43it/s]\n",
            " 90%|█████████ | 153781248/170498071 [00:10<00:00, 17599008.31it/s]\n",
            " 92%|█████████▏| 156566528/170498071 [00:10<00:00, 17146053.30it/s]\n",
            " 94%|█████████▎| 159679488/170498071 [00:10<00:00, 17408985.86it/s]\n",
            " 95%|█████████▌| 162726912/170498071 [00:10<00:00, 17484956.10it/s]\n",
            " 97%|█████████▋| 165790720/170498071 [00:11<00:00, 17567770.43it/s]\n",
            " 99%|█████████▉| 168838144/170498071 [00:11<00:00, 17587734.14it/s]\n",
            "170499072it [00:11, 15139870.82it/s]                               \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(func pid=4190)\u001b[0m Extracting .data/cifar-10-python.tar.gz to .data\n",
            "== Status ==\n",
            "Current time: 2022-03-25 02:52:26 (running for 00:00:16.32)\n",
            "Memory usage on this node: 2.1/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
            "Resources requested: 2.0/2 CPUs, 0/0 GPUs, 0.0/6.68 GiB heap, 0.0/3.34 GiB objects\n",
            "Result logdir: /root/ray_results/DEFAULT_2022-03-25_02-52-10\n",
            "Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n",
            "+---------------------+----------+-----------------+------+------+-------------+--------------+\n",
            "| Trial name          | status   | loc             |   l1 |   l2 |          lr |   batch_size |\n",
            "|---------------------+----------+-----------------+------+------+-------------+--------------|\n",
            "| DEFAULT_90d48_00000 | RUNNING  | 172.28.0.2:4190 |  256 |    8 | 0.00237941  |           16 |\n",
            "| DEFAULT_90d48_00001 | PENDING  |                 |  256 |  128 | 0.0985469   |            4 |\n",
            "| DEFAULT_90d48_00002 | PENDING  |                 |   16 |  128 | 0.000290688 |            8 |\n",
            "| DEFAULT_90d48_00003 | PENDING  |                 |  128 |  256 | 0.00057894  |            2 |\n",
            "| DEFAULT_90d48_00004 | PENDING  |                 |    8 |   16 | 0.00232069  |            4 |\n",
            "| DEFAULT_90d48_00005 | PENDING  |                 |   16 |   64 | 0.0846387   |            4 |\n",
            "| DEFAULT_90d48_00006 | PENDING  |                 |    8 |    4 | 0.000981326 |            2 |\n",
            "| DEFAULT_90d48_00007 | PENDING  |                 |   32 |    8 | 0.00232085  |           16 |\n",
            "| DEFAULT_90d48_00008 | PENDING  |                 |  256 |    4 | 0.00174613  |            8 |\n",
            "| DEFAULT_90d48_00009 | PENDING  |                 |   16 |  256 | 0.000143586 |            8 |\n",
            "+---------------------+----------+-----------------+------+------+-------------+--------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=4190)\u001b[0m Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(func pid=4190)\u001b[0m /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "\u001b[2m\u001b[36m(func pid=4190)\u001b[0m   cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Status ==\n",
            "Current time: 2022-03-25 02:52:31 (running for 00:00:21.35)\n",
            "Memory usage on this node: 2.4/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
            "Resources requested: 2.0/2 CPUs, 0/0 GPUs, 0.0/6.68 GiB heap, 0.0/3.34 GiB objects\n",
            "Result logdir: /root/ray_results/DEFAULT_2022-03-25_02-52-10\n",
            "Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n",
            "+---------------------+----------+-----------------+------+------+-------------+--------------+\n",
            "| Trial name          | status   | loc             |   l1 |   l2 |          lr |   batch_size |\n",
            "|---------------------+----------+-----------------+------+------+-------------+--------------|\n",
            "| DEFAULT_90d48_00000 | RUNNING  | 172.28.0.2:4190 |  256 |    8 | 0.00237941  |           16 |\n",
            "| DEFAULT_90d48_00001 | PENDING  |                 |  256 |  128 | 0.0985469   |            4 |\n",
            "| DEFAULT_90d48_00002 | PENDING  |                 |   16 |  128 | 0.000290688 |            8 |\n",
            "| DEFAULT_90d48_00003 | PENDING  |                 |  128 |  256 | 0.00057894  |            2 |\n",
            "| DEFAULT_90d48_00004 | PENDING  |                 |    8 |   16 | 0.00232069  |            4 |\n",
            "| DEFAULT_90d48_00005 | PENDING  |                 |   16 |   64 | 0.0846387   |            4 |\n",
            "| DEFAULT_90d48_00006 | PENDING  |                 |    8 |    4 | 0.000981326 |            2 |\n",
            "| DEFAULT_90d48_00007 | PENDING  |                 |   32 |    8 | 0.00232085  |           16 |\n",
            "| DEFAULT_90d48_00008 | PENDING  |                 |  256 |    4 | 0.00174613  |            8 |\n",
            "| DEFAULT_90d48_00009 | PENDING  |                 |   16 |  256 | 0.000143586 |            8 |\n",
            "+---------------------+----------+-----------------+------+------+-------------+--------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-25 02:52:36 (running for 00:00:26.37)\n",
            "Memory usage on this node: 2.4/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
            "Resources requested: 2.0/2 CPUs, 0/0 GPUs, 0.0/6.68 GiB heap, 0.0/3.34 GiB objects\n",
            "Result logdir: /root/ray_results/DEFAULT_2022-03-25_02-52-10\n",
            "Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n",
            "+---------------------+----------+-----------------+------+------+-------------+--------------+\n",
            "| Trial name          | status   | loc             |   l1 |   l2 |          lr |   batch_size |\n",
            "|---------------------+----------+-----------------+------+------+-------------+--------------|\n",
            "| DEFAULT_90d48_00000 | RUNNING  | 172.28.0.2:4190 |  256 |    8 | 0.00237941  |           16 |\n",
            "| DEFAULT_90d48_00001 | PENDING  |                 |  256 |  128 | 0.0985469   |            4 |\n",
            "| DEFAULT_90d48_00002 | PENDING  |                 |   16 |  128 | 0.000290688 |            8 |\n",
            "| DEFAULT_90d48_00003 | PENDING  |                 |  128 |  256 | 0.00057894  |            2 |\n",
            "| DEFAULT_90d48_00004 | PENDING  |                 |    8 |   16 | 0.00232069  |            4 |\n",
            "| DEFAULT_90d48_00005 | PENDING  |                 |   16 |   64 | 0.0846387   |            4 |\n",
            "| DEFAULT_90d48_00006 | PENDING  |                 |    8 |    4 | 0.000981326 |            2 |\n",
            "| DEFAULT_90d48_00007 | PENDING  |                 |   32 |    8 | 0.00232085  |           16 |\n",
            "| DEFAULT_90d48_00008 | PENDING  |                 |  256 |    4 | 0.00174613  |            8 |\n",
            "| DEFAULT_90d48_00009 | PENDING  |                 |   16 |  256 | 0.000143586 |            8 |\n",
            "+---------------------+----------+-----------------+------+------+-------------+--------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-25 02:52:41 (running for 00:00:31.41)\n",
            "Memory usage on this node: 2.4/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
            "Resources requested: 2.0/2 CPUs, 0/0 GPUs, 0.0/6.68 GiB heap, 0.0/3.34 GiB objects\n",
            "Result logdir: /root/ray_results/DEFAULT_2022-03-25_02-52-10\n",
            "Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n",
            "+---------------------+----------+-----------------+------+------+-------------+--------------+\n",
            "| Trial name          | status   | loc             |   l1 |   l2 |          lr |   batch_size |\n",
            "|---------------------+----------+-----------------+------+------+-------------+--------------|\n",
            "| DEFAULT_90d48_00000 | RUNNING  | 172.28.0.2:4190 |  256 |    8 | 0.00237941  |           16 |\n",
            "| DEFAULT_90d48_00001 | PENDING  |                 |  256 |  128 | 0.0985469   |            4 |\n",
            "| DEFAULT_90d48_00002 | PENDING  |                 |   16 |  128 | 0.000290688 |            8 |\n",
            "| DEFAULT_90d48_00003 | PENDING  |                 |  128 |  256 | 0.00057894  |            2 |\n",
            "| DEFAULT_90d48_00004 | PENDING  |                 |    8 |   16 | 0.00232069  |            4 |\n",
            "| DEFAULT_90d48_00005 | PENDING  |                 |   16 |   64 | 0.0846387   |            4 |\n",
            "| DEFAULT_90d48_00006 | PENDING  |                 |    8 |    4 | 0.000981326 |            2 |\n",
            "| DEFAULT_90d48_00007 | PENDING  |                 |   32 |    8 | 0.00232085  |           16 |\n",
            "| DEFAULT_90d48_00008 | PENDING  |                 |  256 |    4 | 0.00174613  |            8 |\n",
            "| DEFAULT_90d48_00009 | PENDING  |                 |   16 |  256 | 0.000143586 |            8 |\n",
            "+---------------------+----------+-----------------+------+------+-------------+--------------+\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## save model\n",
        "model_path = './project1_model.pt'\n",
        "torch.save(project1_model.state_dict(), model_path)"
      ],
      "metadata": {
        "id": "ic3Au1eN3JFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#And the saved file can be loaded with the following code.\n",
        "## read model file\n",
        "\n",
        "import torch\n",
        "from project1_model import project1_model\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "model = project1_model().to(device)\n",
        "model_path = './project1_model.pt'\n",
        "model.load_state_dict(torch.load(model_path, map_location=device), strict=False)"
      ],
      "metadata": {
        "id": "XGQxS5826Wu6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}